# üß† Agent 4LB - Agent IA Autonome

> **Statut** : ‚úÖ 100% Fonctionnel  
> **Version** : 1.0.0  
> **Date** : 5 d√©cembre 2025

Agent capable d'ex√©cuter des t√¢ches complexes de mani√®re **100% autonome** en utilisant le pattern ReAct (Reasoning + Acting).

---

## üéØ Fonctionnement

L'agent utilise une boucle autonome :

```
THINK ‚Üí ACT ‚Üí OBSERVE ‚Üí REPEAT
```

1. **THINK** : R√©fl√©chit √† la t√¢che et planifie
2. **ACT** : Choisit et ex√©cute un outil
3. **OBSERVE** : Analyse le r√©sultat
4. **REPEAT** : Continue ou donne la r√©ponse finale

---

## üöÄ D√©marrage

### CLI Interactif
```bash
cd /home/lalpha/projets/ai-tools/agent-4lb
./agent.sh
```

### API REST
```bash
cd /home/lalpha/projets/ai-tools/agent-4lb
./start-api.sh
# API: http://localhost:8889
# Docs: http://localhost:8889/docs
```

---

## üîß 15 Outils Disponibles

| Cat√©gorie | Outils |
|-----------|--------|
| **Syst√®me** | execute_command, read_file, write_file, list_directory, search_files, system_info |
| **Docker** | docker_ps, docker_logs, docker_restart |
| **Git** | git_status, git_commit |
| **R√©seau** | check_url |
| **Ollama** | ollama_list, ollama_run |
| **Service** | service_status |

---

## üìÅ Structure

```
agent-4lb/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ config.py      # Configuration (LLM, chemins, limites)
‚îÇ   ‚îî‚îÄ‚îÄ agent.py       # Classe Agent4LB (boucle ReAct)
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ system_tools.py # 15 outils disponibles
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îú‚îÄ‚îÄ persistent.py  # M√©moire SQLite
‚îÇ   ‚îî‚îÄ‚îÄ agent_memory.db # Base de donn√©es
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ server.py      # API FastAPI (port 8889)
‚îú‚îÄ‚îÄ cli.py             # Interface interactive
‚îú‚îÄ‚îÄ agent.sh           # Script de lancement CLI
‚îú‚îÄ‚îÄ start-api.sh       # Script de lancement API
‚îî‚îÄ‚îÄ README.md
```

---

## üì° API Endpoints

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/` | GET | Info API |
| `/status` | GET | Statut agent + Ollama |
| `/run` | POST | Ex√©cuter une t√¢che autonome |
| `/chat` | POST | Mode conversation |
| `/history` | GET | Historique des t√¢ches |
| `/memory/stats` | GET | Stats m√©moire |
| `/memory/knowledge` | GET/POST | Gestion des connaissances |
| `/sessions` | GET | Sessions actives |
| `/docs` | GET | Documentation Swagger |

---

## ‚öôÔ∏è Configuration

### Variables d'environnement

| Variable | D√©faut | Description |
|----------|--------|-------------|
| `OLLAMA_HOST` | http://localhost:11434 | Host Ollama |
| `OLLAMA_MODEL` | qwen2.5-coder:32b-instruct-q4_K_M | Mod√®le LLM |
| `OLLAMA_TEMPERATURE` | 0.1 | Temp√©rature |
| `API_PORT` | 8889 | Port API |
| `AGENT_MAX_ITERATIONS` | 15 | Limite it√©rations |
| `ANTHROPIC_API_KEY` | (vide) | Cl√© Claude (optionnel) |
| `DEFAULT_LLM` | ollama | LLM: ollama ou claude |

### Fichier config.py

```python
# Chemins importants
INFRA_DIR = /home/lalpha/projets/infrastructure/4lb-docker-stack
PROJECTS_DIR = /home/lalpha/projets
SCRIPTS_DIR = /home/lalpha/scripts
MEMORY_DB_PATH = memory/agent_memory.db
```

---

## üí° Exemples d'utilisation

### Via CLI

```bash
./agent.sh

[TASK] > Liste les conteneurs Docker actifs
[TASK] > V√©rifie l'espace disque et les logs de Traefik
[TASK] > Cr√©e un script de backup PostgreSQL
[TASK] > Analyse les performances du serveur
```

### Via API

```bash
# Ex√©cuter une t√¢che
curl -X POST http://localhost:8889/run \
  -H "Content-Type: application/json" \
  -d '{"task": "Liste les conteneurs Docker actifs"}'

# Mode chat
curl -X POST http://localhost:8889/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Bonjour, comment vas-tu?"}'

# Statut
curl http://localhost:8889/status
```

### Via Python

```python
from core.agent import Agent4LB

agent = Agent4LB()
result = agent.run("V√©rifie l'espace disque")
print(result)
```

---

## üíæ M√©moire Persistante

L'agent utilise SQLite avec 4 tables :

| Table | Usage |
|-------|-------|
| `conversations` | Historique des messages par session |
| `tasks` | T√¢ches ex√©cut√©es avec r√©sultats |
| `knowledge` | Connaissances apprises |
| `errors` | Erreurs pour auto-am√©lioration |

---

## üñ•Ô∏è Serveur Cible

| Composant | Valeur |
|-----------|--------|
| **Hostname** | lalpha-server-1 |
| **OS** | Ubuntu 25.10 |
| **CPU** | AMD Ryzen 9 7900X (24 cores) |
| **RAM** | 64 GB DDR5 |
| **GPU** | NVIDIA RTX 5070 Ti (16 GB VRAM) |
| **IP** | 10.10.10.46 (VLAN 2) |

---

## üîó Voir aussi

- **Orchestrateur 4LB** : `/home/lalpha/projets/ai-tools/orchestrator-4lb/` (automatisation cron)
- **Documentation** : `/home/lalpha/documentation/`
- **MCP Servers** : `/home/lalpha/projets/ai-tools/mcp-servers/`

---

*Cr√©√© le 4 d√©cembre 2025 - Mis √† jour le 5 d√©cembre 2025*
